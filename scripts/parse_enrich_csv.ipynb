{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DHd Affiliations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aim: parse XML file, generate a CSV for manual refinement in Open Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                          affiliations_distinct_distinct.xml\r\n",
      "affiliations_alle.xml              \u001b[34mscripts\u001b[m\u001b[m\r\n",
      "affiliations_distinct.xml\r\n"
     ]
    }
   ],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../affiliations_distinct_distinct.xml'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_source_file_name = \"affiliations_distinct_distinct.xml\"\n",
    "xml_source_file_path = \"../\" + xml_source_file_name \n",
    "xml_source_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "xml = ET.parse(xml_source_file_path)\n",
    "xml = xml.getroot()\n",
    "\n",
    "affiliation_elems = xml.findall(\"affiliation\")\n",
    "len(affiliation_elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Austrian Centre for Digital Humanities and Cultural Heritage'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliation_elems[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_rule_based(value:str):\n",
    "    \"\"\"\n",
    "    Rule-based detection of country by simple string matching\n",
    "    \"\"\"\n",
    "    if value != None:\n",
    "        \n",
    "        #try rule-based detection of country\n",
    "        if \"Österreich\" in value:\n",
    "            return \"Österreich\"\n",
    "        elif \"Austria\" in value:\n",
    "            return \"Österreich\"\n",
    "        elif \"Deutschland\" in value:\n",
    "            return \"Deutschland\"\n",
    "        elif \"Germany\" in value:\n",
    "            return \"Deutschland\"\n",
    "        elif \"Schweiz\" in value:\n",
    "            return \"Schweiz\"\n",
    "        elif \"Switzerland\" in value:\n",
    "            return \"Schweiz\"\n",
    "        \n",
    "        #found some other countries in the GPE detected by NLTK and updated the function\n",
    "        elif \"Greece\" in value:\n",
    "            return \"Griechenland\"\n",
    "        elif \"Griechenland\" in value:\n",
    "            return \"Griechenland\"\n",
    "        elif \"United Kingdom\" in value:\n",
    "            return \"Vereinigtes Königreich\"\n",
    "        elif \"Vereinigtes Königreich\" in value:\n",
    "            return \"Vereinigtes Königreich\"\n",
    "        elif \"Indien\" in value:\n",
    "            return \"Indien\"\n",
    "        elif \"Italien\" in value:\n",
    "            return \"Italien\"\n",
    "        elif \"Russland\" in value:\n",
    "            return \"Russland\"\n",
    "        elif \"Russia\" in value:\n",
    "            return \"Russland\"\n",
    "        elif \"Canada\" in value:\n",
    "            return \"Kanada\"\n",
    "        elif \"Norwegen\" in value:\n",
    "            return \"Norwegen\"\n",
    "        elif \"Norway\" in value:\n",
    "            return \"Norwegen\"\n",
    "        elif \"Australien\" in value:\n",
    "            return \"Australien\"\n",
    "        elif \"Serbien\" in value:\n",
    "            return \"Serbien\"\n",
    "        elif \"Estland\" in value:\n",
    "            return \"Estland\"\n",
    "        elif \"Niederlande\" in value:\n",
    "            return \"Niederlande\"\n",
    "        elif \"Israel\" in value:\n",
    "            return \"Israel\"\n",
    "        elif \"Irland\" in value:\n",
    "            return \"Irland\"\n",
    "        elif \"Ireland\" in value:\n",
    "            return \"Irland\"\n",
    "        elif \"Spain\" in value:\n",
    "            return \"Spanien\"\n",
    "        elif \"Spanien\" in value:\n",
    "            return \"Spanien\"\n",
    "        elif \"Portugal\" in value:\n",
    "            return \"Portugal\"\n",
    "        elif \"Belgien\" in value:\n",
    "            return \"Belgien\"\n",
    "        elif \"France\" in value:\n",
    "            return \"Frankreich\"\n",
    "        elif \"Frankreich\" in value:\n",
    "            return \"Frankreich\"\n",
    "        elif \"China\" in value:\n",
    "            return \"China\"\n",
    "        elif \"Taiwan\" in value:\n",
    "            return \"Taiwan\"\n",
    "        \n",
    "    \n",
    "        else: \n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download xx_ent_wiki_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "NER = spacy.load(\"xx_ent_wiki_sm\")\n",
    "def ner_spacy(value:str):\n",
    "    ents = NER(value)\n",
    "    #for ent in ents.ents:\n",
    "    #print(ent.text,ent.label_)\n",
    "    result = []\n",
    "    for ent in ents.ents:\n",
    "        result_item = {}\n",
    "        result_item[\"text\"] = ent.text\n",
    "        result_item[\"type\"] = ent.label_\n",
    "        result.append(result_item)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/ingoboerner/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ingoboerner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/ingoboerner/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ingoboerner/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_nltk(value:str):\n",
    "    result= []\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(value))):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            #print(chunk.label(), ' '.join(c[0] for c in chunk))\n",
    "            if chunk.label() == \"GPE\":\n",
    "                chunk_text = ' '.join(c[0] for c in chunk)\n",
    "                #print(chunk_text)\n",
    "                result.append(chunk_text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_nltk(\"École polytechnique fédérale de Lausanne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliations = []\n",
    "for affiliation_elem in affiliation_elems:\n",
    "    affiliation = {}\n",
    "    if affiliation_elem.text != None:\n",
    "        orig_string = affiliation_elem.text.strip().replace(\"\\n\",\"\")\n",
    "        orig_string = re.sub(' +', ' ', orig_string)\n",
    "        affiliation[\"orig_string\"] = orig_string\n",
    "        #try simple rule-based detection of country\n",
    "        affiliation[\"country\"] = get_country_rule_based(orig_string)\n",
    "    \n",
    "        # NER\n",
    "        affiliation[\"spacy_entities\"] = ner_spacy(orig_string)\n",
    "        affiliation[\"nltk_gpe\"] = ner_nltk(orig_string)\n",
    "    \n",
    "    # add enriched to array \n",
    "    affiliations.append(affiliation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orig_string': 'The University of Edinburgh, Law School, Vereinigtes Königreich',\n",
       " 'country': 'Vereinigtes Königreich',\n",
       " 'spacy_entities': [{'text': 'University of Edinburgh', 'type': 'ORG'}],\n",
       " 'nltk_gpe': ['Edinburgh']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations[220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and clean a list of gpe detected by nltk\n",
    "nltk_gpe_vals = []\n",
    "for aff in affiliations:\n",
    "    if \"nltk_gpe\" in aff:\n",
    "        for gpe in aff[\"nltk_gpe\"]:\n",
    "            if gpe not in nltk_gpe_vals:\n",
    "                nltk_gpe_vals.append(gpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_gpe_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "jsonString = json.dumps(nltk_gpe_vals)\n",
    "jsonFile = open(\"nltk_gpe_vals.json\", \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually cleaning this file, should be loaded again and used to detect cities. When cleaning I also found some additional countries, that were added to the rule-based function above; will be run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orig_string': 'Centar za digitalne humanističke nauke, Serbien',\n",
       " 'country': 'Serbien',\n",
       " 'spacy_entities': [],\n",
       " 'nltk_gpe': ['Serbien']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations[415]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orig_string': 'Austrian Centre for Digital Humanities and Cultural Heritage',\n",
       " 'country': 'Österreich',\n",
       " 'spacy_entities': [{'text': 'Austrian Centre for Digital Humanities',\n",
       "   'type': 'ORG'}],\n",
       " 'nltk_gpe': ['Austrian']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cities, that where detected by nltk as GPE and cleaned manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('nltk_gpe_vals.json') as f:\n",
    "    cities = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Moskau',\n",
       " 'Hagen',\n",
       " 'Bochum',\n",
       " 'Graz',\n",
       " 'Köln',\n",
       " 'Trier',\n",
       " 'Zurich',\n",
       " 'Freiburg',\n",
       " 'Rom',\n",
       " 'Mainz',\n",
       " 'Leipzig',\n",
       " 'Halle',\n",
       " 'Kraków',\n",
       " 'Edinburgh',\n",
       " 'Passau',\n",
       " 'Basel',\n",
       " 'Bern',\n",
       " 'Saarbrücken',\n",
       " 'Passau',\n",
       " 'Wien',\n",
       " 'Hamburg',\n",
       " 'Berlin',\n",
       " 'Roma',\n",
       " 'Frankfurt',\n",
       " 'Paris',\n",
       " 'Victoria',\n",
       " 'Mannheim',\n",
       " 'Oslo',\n",
       " 'Illinois',\n",
       " 'Bonn',\n",
       " 'Lonfon',\n",
       " 'New Mexico',\n",
       " 'Jena',\n",
       " 'Amsterdam',\n",
       " 'Basel',\n",
       " 'Cambridge',\n",
       " 'Sheffield',\n",
       " 'Verona',\n",
       " 'Italy',\n",
       " 'Wien',\n",
       " 'Lausanne',\n",
       " 'Umea',\n",
       " 'Jena',\n",
       " 'Beijing',\n",
       " 'Salzburg',\n",
       " 'Semedia',\n",
       " 'Ancona',\n",
       " 'Konstanz',\n",
       " 'València',\n",
       " 'Bergen',\n",
       " 'Kassel']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aff in affiliations:\n",
    "    if 'orig_string' in aff:\n",
    "        for city in cities:\n",
    "            if city in aff['orig_string']:\n",
    "                aff[\"city\"] = city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orig_string': 'Berlin-Brandenburgische Akademie der Wissenschaften',\n",
       " 'country': None,\n",
       " 'spacy_entities': [{'text': 'Berlin-Brandenburgische Akademie der Wissenschaften',\n",
       "   'type': 'ORG'}],\n",
       " 'nltk_gpe': [],\n",
       " 'city': 'Berlin'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orig_string': 'The University of Edinburgh, Law School, Vereinigtes Königreich',\n",
       " 'country': 'Vereinigtes Königreich',\n",
       " 'spacy_entities': [{'text': 'University of Edinburgh', 'type': 'ORG'}],\n",
       " 'nltk_gpe': ['Edinburgh'],\n",
       " 'city': 'Edinburgh'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations[220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orig_string': 'TU Berlin, Deutschland',\n",
       " 'country': 'Deutschland',\n",
       " 'spacy_entities': [{'text': 'TU Berlin', 'type': 'ORG'},\n",
       "  {'text': 'Deutschland', 'type': 'LOC'}],\n",
       " 'nltk_gpe': ['Deutschland'],\n",
       " 'city': 'Berlin'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations[221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orig_string': 'Bibliotheca Hertziana, Rom, Italien',\n",
       " 'country': 'Italien',\n",
       " 'spacy_entities': [{'text': 'Bibliotheca Hertziana', 'type': 'LOC'}],\n",
       " 'nltk_gpe': ['Rom', 'Italien'],\n",
       " 'city': 'Rom'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'orig_string': 'TU Dresden, Deutschland',\n",
       " 'country': 'Deutschland',\n",
       " 'spacy_entities': [{'text': 'TU Dresden', 'type': 'ORG'},\n",
       "  {'text': 'Deutschland', 'type': 'LOC'}],\n",
       " 'nltk_gpe': ['Deutschland']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations[225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(affiliations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a csv and clean in Open Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "header = ['orig_string', 'country', 'city']\n",
    "\n",
    "with open('affiliations_openrefine.csv', 'w', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    for aff in affiliations:\n",
    "        row = []\n",
    "        for col in header:\n",
    "            if col in aff:\n",
    "                row.append(aff[col])\n",
    "            else:\n",
    "                row.append(\"\")\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
